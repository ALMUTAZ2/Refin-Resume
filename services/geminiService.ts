import { AnalysisResult, JobMatchResult, ResumeSection, ImprovedContent } from "../types";

export class GeminiService {
  
  private async callBackend(action: string, payload: any): Promise<any> {
    try {
      const response = await fetch('/api/groq', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ action, payload })
      });

      if (!response.ok) {
        throw new Error(`Server Error: ${response.statusText}`);
      }

      return await response.json();
    } catch (error) {
      console.error(`Failed to call backend for ${action}:`, error);
      throw error;
    }
  }

  async analyzeResume(text: string): Promise<AnalysisResult> {
    const data = await this.callBackend('analyze', { text });
    return {
      detectedRole: data.extractedHeadlines?.[0] || "Unknown",
      parsingFlags: data.parsingFlags || {},
      hardSkillsFound: data.hardSkillsFound || [],
      softSkillsFound: data.softSkillsFound || [],
      missingHardSkills: [],
      metrics: data.metrics || {},
      formattingIssues: data.formattingIssues || [],
      criticalErrors: [],
      strengths: [],
      weaknesses: [],
      summaryFeedback: data.summaryFeedback || "Done",
      structuredSections: data.structuredSections || [],
      overallScore: data.overallScore || 50
    };
  }

  // ============================================================
  // ğŸ§  Ø§Ù„Ø­Ù„ Ø§Ù„Ø°ÙƒÙŠ: Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ (Smart Dynamic Batching)
  // ÙŠÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø³Ø±Ø¹Ø© Vercel ÙˆØªÙˆÙÙŠØ± Ø§Ù„ØªÙˆÙƒÙ†Ø²
  // ============================================================
  async bulkImproveATS(sections: ResumeSection[]): Promise<Record<string, string>> { 
    
    // Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ø¢Ù…Ù†Ø© (Ù„ÙƒÙŠ Ù„Ø§ ÙŠÙ†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ ÙÙŠ Vercel)
    // Llama 70B ÙŠØ¹Ø§Ù„Ø¬ Ø­ÙˆØ§Ù„ÙŠ 300 ÙƒÙ„Ù…Ø© Ø¨Ø³Ø±Ø¹Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù€ 10 Ø«ÙˆØ§Ù†ÙŠ
    const MAX_WORDS_PER_BATCH = 250; 

    const batches: ResumeSection[][] = [];
    let currentBatch: ResumeSection[] = [];
    let currentBatchWordCount = 0;

    // 1. Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªÙˆØ²ÙŠØ¹
    for (const section of sections) {
        const sectionWords = section.content.split(/\s+/).length;
        const isHeavySection = section.title.toLowerCase().includes('experience') || section.title.toLowerCase().includes('work');

        // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø³Ù… "Ø«Ù‚ÙŠÙ„" Ø¬Ø¯Ø§Ù‹ (Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ø¯)ØŒ Ù†Ø¶Ø¹Ù‡ ÙÙŠ Ø­Ø²Ù…Ø© Ù„ÙˆØ­Ø¯Ù‡ ÙÙˆØ±Ø§Ù‹
        if (isHeavySection && sectionWords > 150) {
            // Ù†ØºÙ„Ù‚ Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¥Ø°Ø§ ÙÙŠÙ‡Ø§ Ø¹Ù†Ø§ØµØ±
            if (currentBatch.length > 0) {
                batches.push(currentBatch);
                currentBatch = [];
                currentBatchWordCount = 0;
            }
            // Ù†Ø¶ÙŠÙ Ø§Ù„Ø«Ù‚ÙŠÙ„ ÙƒØ­Ø²Ù…Ø© Ù…Ø³ØªÙ‚Ù„Ø©
            batches.push([section]);
            continue;
        }

        // Ø¥Ø°Ø§ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø³Ù… Ø³ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ØŒ Ù†ØºÙ„Ù‚ Ø§Ù„Ø­Ø²Ù…Ø© ÙˆÙ†ÙØªØ­ Ø¬Ø¯ÙŠØ¯Ø©
        if (currentBatchWordCount + sectionWords > MAX_WORDS_PER_BATCH) {
            batches.push(currentBatch);
            currentBatch = [];
            currentBatchWordCount = 0;
        }

        // Ù†Ø¶ÙŠÙ Ø§Ù„Ù‚Ø³Ù… Ù„Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        currentBatch.push(section);
        currentBatchWordCount += sectionWords;
    }

    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙˆØ§Ù‚ÙŠ
    if (currentBatch.length > 0) {
        batches.push(currentBatch);
    }

    console.log(`Smart Batching: Optimized into ${batches.length} requests (instead of ${sections.length}).`);

    // 2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø­Ø²Ù… Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ (Parallel Execution)
    const promises = batches.map(async (batchSections) => {
        try {
            // Ù†Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ± (bulk_improve)
            // Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…Ø¬Ù‡Ø² Ù„ÙŠØ³ØªÙ‚Ø¨Ù„ Ù…ØµÙÙˆÙØ©ØŒ Ù„Ø°Ø§ Ø³ÙŠØ¹Ù…Ù„ ÙÙˆØ±Ø§Ù‹
            const result = await this.callBackend('bulk_improve', { sections: batchSections });
            return result; // ÙŠØ¹ÙŠØ¯ ÙƒØ§Ø¦Ù† { id: content, id2: content }
        } catch (e) {
            console.error("Batch failed", e);
            // ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø­Ø²Ù…Ø©ØŒ Ù†Ø¹ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù„Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ØªÙŠ ÙÙŠÙ‡Ø§ Ø­ØªÙ‰ Ù„Ø§ ØªØ®ØªÙÙŠ
            const fallback: Record<string, string> = {};
            batchSections.forEach(s => fallback[s.id] = s.content);
            return fallback;
        }
    });

    // 3. ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø²Ù…
    const results = await Promise.all(promises);
    
    const finalMapping: Record<string, string> = {};
    results.forEach(chunkResult => {
        Object.assign(finalMapping, chunkResult);
    });
    
    return finalMapping;
  }

  async improveSection(title: string, content: string): Promise<ImprovedContent> {
    return await this.callBackend('improve', { title, content });
  }

  async matchJobDescription(resumeText: string, sections: any[], jd: string): Promise<JobMatchResult> {
    const data = await this.callBackend('match', { resume: resumeText, jd });
    return {
      matchingKeywords: data.matchedCoreKeywords || [],
      missingKeywords: data.missingCoreKeywords || [],
      matchFeedback: data.matchFeedback || "",
      matchPercentage: data.matchPercentage || 0,
      tailoredSections: []
    };
  }
}

